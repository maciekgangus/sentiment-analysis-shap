{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import re\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from transformers import logging\n",
    "from torchinfo import summary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import random\n",
    "logging.set_verbosity_error()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:08:19.153205Z",
     "start_time": "2025-06-16T21:08:15.190083Z"
    }
   },
   "id": "791bff12d3f3fcc4",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def combine_text(row):\n",
    "    content = row['content'] if pd.notna(row['content']) else ''\n",
    "    hashtags = row['hashtags'] if pd.notna(row['hashtags']) else ''\n",
    "    mentions = row['mentions'] if pd.notna(row['mentions']) else ''\n",
    "    return f\"{content} {hashtags} {mentions}\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:08:23.004898Z",
     "start_time": "2025-06-16T21:08:23.001559Z"
    }
   },
   "id": "39a09af0e064a5df",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"realdonaldtrump.csv\")\n",
    "\n",
    "tweets_df[\"text_full\"] = tweets_df.apply(combine_text, axis=1)\n",
    "\n",
    "def clean_tweet_for_vader(text):\n",
    "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)\n",
    "    text = re.sub(r\"#\", \"\", text)        \n",
    "    text = re.sub(r\"@\", \"\", text)     \n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "tweets_df[\"text_clean\"] = tweets_df[\"text_full\"].apply(clean_tweet_for_vader)\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer() # model dart vader\n",
    "tweets_df[\"vader_scores\"] = tweets_df[\"text_clean\"].apply(analyzer.polarity_scores)\n",
    "tweets_df = pd.concat([tweets_df, tweets_df[\"vader_scores\"].apply(pd.Series)], axis=1)\n",
    "\n",
    "\n",
    "def classify_sentiment(score):\n",
    "    if score >= 0.05:\n",
    "        return \"positive\"\n",
    "    elif score <= -0.05:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "tweets_df[\"sentiment_label\"] = tweets_df[\"compound\"].apply(classify_sentiment)\n",
    "\n",
    "def sentiment_to_number(sentiment):\n",
    "    if sentiment == 'neutral':\n",
    "        return 0\n",
    "    elif sentiment == 'positive':\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "del tweets_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-02T18:55:08.804920Z",
     "start_time": "2025-06-02T18:55:02.683435Z"
    }
   },
   "id": "c54ca8b4faeb0e11",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def preprocess_tweet_bert(text):\n",
    "    text = re.sub(r\"http\\S+\", \"http\", text)\n",
    "    text = re.sub(r\"pic\\.twitter\\.com/\\S+\", \"<IMG>\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    text = re.sub(r\"@\\S+\", \"@user\", text).strip()\n",
    "    text = re.sub(r'@ +\\w+', '@user', text)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:08:29.028939Z",
     "start_time": "2025-06-16T21:08:29.026621Z"
    }
   },
   "id": "b5cafd38ce8c8d25",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def tokenize_and_save_stream(data, tokenizer_type, batch_size=32, file_path=\"tokenized_batches.pkl\"):\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pass\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i:i + batch_size]\n",
    "        encoded_inputs = tokenizer_type(batch, padding=True, truncation=True, max_length=32, return_tensors=\"pt\")\n",
    "        batch_dict = {k: v.tolist() for k, v in encoded_inputs.items()}\n",
    "        with open(file_path, \"ab\") as f:\n",
    "            pickle.dump(batch_dict, f)\n",
    "    print(f\"Tokeny zapisane do pliku {file_path}\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:08:29.924591Z",
     "start_time": "2025-06-16T21:08:29.919582Z"
    }
   },
   "id": "6e1a04bf4264e40c",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_tokenized_batches_stream(model_, device, file_path=\"tokenized_batches.pkl\"):\n",
    "    model_.eval()\n",
    "    results = []\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        while True:\n",
    "            try:\n",
    "                batch_dict = pickle.load(f)\n",
    "                batch_tensors = {k: torch.tensor(v).to(device) for k, v in batch_dict.items()}\n",
    "                with torch.no_grad():\n",
    "                    outputs = model_(**batch_tensors)\n",
    "                \n",
    "                logits = outputs.logits\n",
    "                probs = F.softmax(logits, dim=1)\n",
    "                predicted_classes = torch.argmax(probs, dim=1)\n",
    "                \n",
    "                results.append((predicted_classes.cpu().numpy(), probs.cpu().numpy()))\n",
    "            except EOFError:\n",
    "                break\n",
    "        return results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:08:30.427303Z",
     "start_time": "2025-06-16T21:08:30.424320Z"
    }
   },
   "id": "23f4c7438740b7aa",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "===================================================================================================================\nLayer (type:depth-idx)                                            Output Shape              Param #\n===================================================================================================================\nRobertaForSequenceClassification                                  [1, 3]                    --\n├─RobertaModel: 1-1                                               [1, 32, 768]              --\n│    └─RobertaEmbeddings: 2-1                                     [1, 32, 768]              --\n│    │    └─Embedding: 3-1                                        [1, 32, 768]              38,603,520\n│    │    └─Embedding: 3-2                                        [1, 32, 768]              768\n│    │    └─Embedding: 3-3                                        [1, 32, 768]              394,752\n│    │    └─LayerNorm: 3-4                                        [1, 32, 768]              1,536\n│    │    └─Dropout: 3-5                                          [1, 32, 768]              --\n│    └─RobertaEncoder: 2-2                                        [1, 32, 768]              --\n│    │    └─ModuleList: 3-6                                       --                        85,054,464\n├─RobertaClassificationHead: 1-2                                  [1, 3]                    --\n│    └─Dropout: 2-3                                               [1, 768]                  --\n│    └─Linear: 2-4                                                [1, 768]                  590,592\n│    └─Dropout: 2-5                                               [1, 768]                  --\n│    └─Linear: 2-6                                                [1, 3]                    2,307\n===================================================================================================================\nTotal params: 124,647,939\nTrainable params: 124,647,939\nNon-trainable params: 0\nTotal mult-adds (Units.MEGABYTES): 124.65\n===================================================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 26.74\nParams size (MB): 498.59\nEstimated Total Size (MB): 525.34\n==================================================================================================================="
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytanie danych\n",
    "data_bert_df = pd.read_csv(\"realdonaldtrump.csv\")\n",
    "\n",
    "# Preprocessing\n",
    "data_bert_df['combined_tweet'] = data_bert_df.apply(combine_text, axis=1)\n",
    "data_bert_df['combined_tweet_cleared'] = data_bert_df['combined_tweet'].apply(preprocess_tweet_bert)\n",
    "\n",
    "# Ładowanie modelu\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.to(\"mps\")\n",
    "input_ids = torch.randint(0, 1000, (1, 32), dtype=torch.long).to(\"mps\")\n",
    "attention_mask = torch.ones((1, 32), dtype=torch.long).to(\"mps\")\n",
    "summary(model, input_data=(input_ids, attention_mask), device=\"mps\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:08:49.047170Z",
     "start_time": "2025-06-16T21:08:32.499789Z"
    }
   },
   "id": "630ef2c5d938927",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "texts = data_bert_df['combined_tweet_cleared'].tolist()\n",
    "# tokenize_and_save_stream(texts, tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:08:54.723630Z",
     "start_time": "2025-06-16T21:08:54.715140Z"
    }
   },
   "id": "a5f66f4b211e53a0",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                          combined_tweet sentiment_label  \\\n0      Be sure to tune in and watch Donald Trump on L...         neutral   \n1      Donald Trump will be appearing on The View tom...        positive   \n2      Donald Trump reads Top Ten Financial Tips on L...        positive   \n3      New Blog Post: Celebrity Apprentice Finale and...         neutral   \n4      \"My persona will never be that of a wallflower...         neutral   \n...                                                  ...             ...   \n43347  Joe Biden was a TOTAL FAILURE in Government. H...        negative   \n43348  Will be interviewed on @user tonight at 9:00 P...        positive   \n43349                                              <IMG>         neutral   \n43350                                              <IMG>         neutral   \n43351                                              <IMG>         neutral   \n\n                                 sentiment_probabilities  \n0      [0.00428333505988121, 0.6332980990409851, 0.36...  \n1      [0.003935575485229492, 0.4739065170288086, 0.5...  \n2      [0.004720405209809542, 0.12900030612945557, 0....  \n3      [0.004224149510264397, 0.7814801335334778, 0.2...  \n4      [0.23554037511348724, 0.5717381834983826, 0.19...  \n...                                                  ...  \n43347  [0.9519144296646118, 0.04053443297743797, 0.00...  \n43348  [0.0016347389901056886, 0.07318022102117538, 0...  \n43349  [0.0871957391500473, 0.8049344420433044, 0.107...  \n43350  [0.0871957391500473, 0.8049344420433044, 0.107...  \n43351  [0.0871957391500473, 0.8049344420433044, 0.107...  \n\n[43352 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>combined_tweet</th>\n      <th>sentiment_label</th>\n      <th>sentiment_probabilities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Be sure to tune in and watch Donald Trump on L...</td>\n      <td>neutral</td>\n      <td>[0.00428333505988121, 0.6332980990409851, 0.36...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Donald Trump will be appearing on The View tom...</td>\n      <td>positive</td>\n      <td>[0.003935575485229492, 0.4739065170288086, 0.5...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n      <td>positive</td>\n      <td>[0.004720405209809542, 0.12900030612945557, 0....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n      <td>neutral</td>\n      <td>[0.004224149510264397, 0.7814801335334778, 0.2...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"My persona will never be that of a wallflower...</td>\n      <td>neutral</td>\n      <td>[0.23554037511348724, 0.5717381834983826, 0.19...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43347</th>\n      <td>Joe Biden was a TOTAL FAILURE in Government. H...</td>\n      <td>negative</td>\n      <td>[0.9519144296646118, 0.04053443297743797, 0.00...</td>\n    </tr>\n    <tr>\n      <th>43348</th>\n      <td>Will be interviewed on @user tonight at 9:00 P...</td>\n      <td>positive</td>\n      <td>[0.0016347389901056886, 0.07318022102117538, 0...</td>\n    </tr>\n    <tr>\n      <th>43349</th>\n      <td>&lt;IMG&gt;</td>\n      <td>neutral</td>\n      <td>[0.0871957391500473, 0.8049344420433044, 0.107...</td>\n    </tr>\n    <tr>\n      <th>43350</th>\n      <td>&lt;IMG&gt;</td>\n      <td>neutral</td>\n      <td>[0.0871957391500473, 0.8049344420433044, 0.107...</td>\n    </tr>\n    <tr>\n      <th>43351</th>\n      <td>&lt;IMG&gt;</td>\n      <td>neutral</td>\n      <td>[0.0871957391500473, 0.8049344420433044, 0.107...</td>\n    </tr>\n  </tbody>\n</table>\n<p>43352 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_results = load_tokenized_batches_stream(model, device=\"mps\")\n",
    "# Połączenie wyników z partii\n",
    "sentiment_classes = []\n",
    "sentiment_probs = []\n",
    "for batch_class, batch_prob in batch_results:\n",
    "    sentiment_classes.extend(batch_class)\n",
    "    sentiment_probs.extend(batch_prob.tolist())\n",
    "\n",
    "# Dodanie wyników do DataFrame\n",
    "bert_result_df = pd.DataFrame({\n",
    "    'combined_tweet': texts,\n",
    "    'sentiment_class': sentiment_classes,\n",
    "    'sentiment_probabilities': sentiment_probs\n",
    "})\n",
    "\n",
    "# Mapowanie wyników na etykiety\n",
    "bert_result_df['sentiment_label'] = bert_result_df['sentiment_class'].map({0: 'negative', 1: 'neutral', 2: 'positive'})\n",
    "\n",
    "# Wyświetlenie wyników\n",
    "bert_result_df[['combined_tweet', 'sentiment_label', 'sentiment_probabilities']]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:11:04.115605Z",
     "start_time": "2025-06-16T21:08:55.829015Z"
    }
   },
   "id": "efa63ac3556b05e8",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def preprocess_simple_tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"<URL>\", text)\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:11:46.051154Z",
     "start_time": "2025-06-16T21:11:46.048915Z"
    }
   },
   "id": "386ac3ee140e1795",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   tweet sentiment_label  \\\n0      be sure to tune in and watch donald trump on l...         neutral   \n1      donald trump will be appearing on the view tom...        positive   \n2      donald trump reads top ten financial tips on l...        positive   \n3      new blog post celebrity apprentice finale and ...         neutral   \n4      my persona will never be that of a wallflower ...         neutral   \n...                                                  ...             ...   \n43347  joe biden was a total failure in government he...        negative   \n43348  will be interviewed on user tonight at 900 pm ...        positive   \n43349                                                img         neutral   \n43350                                                img         neutral   \n43351                                                img         neutral   \n\n       sentiment_label_numeric  \n0                            1  \n1                            2  \n2                            2  \n3                            1  \n4                            1  \n...                        ...  \n43347                        0  \n43348                        2  \n43349                        1  \n43350                        1  \n43351                        1  \n\n[43352 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet</th>\n      <th>sentiment_label</th>\n      <th>sentiment_label_numeric</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>be sure to tune in and watch donald trump on l...</td>\n      <td>neutral</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>donald trump will be appearing on the view tom...</td>\n      <td>positive</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>donald trump reads top ten financial tips on l...</td>\n      <td>positive</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>new blog post celebrity apprentice finale and ...</td>\n      <td>neutral</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>my persona will never be that of a wallflower ...</td>\n      <td>neutral</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43347</th>\n      <td>joe biden was a total failure in government he...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43348</th>\n      <td>will be interviewed on user tonight at 900 pm ...</td>\n      <td>positive</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>43349</th>\n      <td>img</td>\n      <td>neutral</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43350</th>\n      <td>img</td>\n      <td>neutral</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43351</th>\n      <td>img</td>\n      <td>neutral</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>43352 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = pd.DataFrame({\n",
    "    'tweet': bert_result_df['combined_tweet'].apply(preprocess_simple_tokenize),\n",
    "    'sentiment_label': bert_result_df['sentiment_label'],\n",
    "    'sentiment_label_numeric': bert_result_df['sentiment_label'].map({'negative': 0, 'neutral': 1, 'positive': 2})\n",
    "})\n",
    "X_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:11:48.520815Z",
     "start_time": "2025-06-16T21:11:48.262425Z"
    }
   },
   "id": "5687035c8097494e",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model MLP\n",
    "---\n",
    "## Architecture\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9815e94d74788667"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "word2idx = {'<pad>': 0, '<unk>': 1}\n",
    "for tweet in X_data['tweet']:\n",
    "    for word in tweet.split():\n",
    "        if word not in word2idx:\n",
    "            word2idx[word] = len(word2idx)\n",
    "\n",
    "def tokenize(tweets, word2idx):\n",
    "    tokenized = []\n",
    "    for tweet in tweets:\n",
    "        indices = [word2idx.get(word, word2idx['<unk>']) for word in tweet.split()]\n",
    "        tokenized.append(indices)\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "tokenized_tweets = tokenize(X_data['tweet'], word2idx)\n",
    "max_len = max(len(t) for t in tokenized_tweets)\n",
    "padded_tweets = [t + [word2idx['<pad>']] * (max_len - len(t)) for t in tokenized_tweets]\n",
    "\n",
    "\n",
    "X = torch.tensor(padded_tweets, dtype=torch.long)\n",
    "y = torch.tensor(X_data['sentiment_label_numeric'], dtype=torch.long)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:17:43.050746Z",
     "start_time": "2025-06-16T21:17:42.066352Z"
    }
   },
   "id": "79c906da6e6620e3",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MLPWithMeanPooling(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dims, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2idx['<pad>'])\n",
    "\n",
    "        layers = []\n",
    "        input_dim = embedding_dim  # po uśrednieniu\n",
    "        for hdim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hdim))\n",
    "            layers.append(nn.BatchNorm1d(hdim))\n",
    "            layers.append(nn.LeakyReLU())\n",
    "            layers.append(nn.Dropout(0.5))\n",
    "            input_dim = hdim\n",
    "\n",
    "        layers.append(nn.Linear(input_dim, output_dim))\n",
    "        self.fc = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # (batch, seq, emb)\n",
    "        mask = (x != word2idx['<pad>']).unsqueeze(2)  # (batch, seq, 1)\n",
    "        masked_emb = embedded * mask  # zero-out padding\n",
    "        pooled = masked_emb.sum(dim=1) / mask.sum(dim=1).clamp(min=1)  # średnia tylko z prawdziwych słów\n",
    "        return self.fc(pooled)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:17:43.961828Z",
     "start_time": "2025-06-16T21:17:43.956862Z"
    }
   },
   "id": "2d55c2365f044504",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = MLPWithMeanPooling(vocab_size=len(word2idx), embedding_dim=100,\n",
    "                           hidden_dims=[64, 32], output_dim=3).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:17:45.961280Z",
     "start_time": "2025-06-16T21:17:45.578360Z"
    }
   },
   "id": "2554807c8608b847",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.9495, Acc=0.5434\n",
      "Epoch 2: Loss=0.7657, Acc=0.6693\n",
      "Epoch 3: Loss=0.6691, Acc=0.7244\n",
      "Epoch 4: Loss=0.6009, Acc=0.7590\n",
      "Epoch 5: Loss=0.5507, Acc=0.7822\n",
      "Epoch 6: Loss=0.5065, Acc=0.8062\n",
      "Epoch 7: Loss=0.4711, Acc=0.8232\n",
      "Epoch 8: Loss=0.4372, Acc=0.8367\n",
      "Epoch 9: Loss=0.4077, Acc=0.8507\n",
      "Epoch 10: Loss=0.3844, Acc=0.8599\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    correct, total, running_loss = 0, 0, 0.0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * batch_x.size(0)\n",
    "        correct += (outputs.argmax(1) == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Loss={running_loss/total:.4f}, Acc={correct/total:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:18:29.235013Z",
     "start_time": "2025-06-16T21:17:48.972996Z"
    }
   },
   "id": "38f83b8fb179bc89",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.6313\n",
      "Test Accuracy: 0.7594\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.81      0.77      2463\n",
      "     neutral       0.66      0.61      0.63      2404\n",
      "    positive       0.84      0.82      0.83      3804\n",
      "\n",
      "    accuracy                           0.76      8671\n",
      "   macro avg       0.74      0.75      0.74      8671\n",
      "weighted avg       0.76      0.76      0.76      8671\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[2002  299  162]\n",
      " [ 518 1456  430]\n",
      " [ 230  447 3127]]\n",
      "Sample 6433: True: neutral, Predicted: neutral\n",
      "Sample 6656: True: positive, Predicted: positive\n",
      "Sample 3956: True: negative, Predicted: negative\n",
      "Sample 6452: True: neutral, Predicted: neutral\n",
      "Sample 3373: True: positive, Predicted: positive\n",
      "Sample 2028: True: positive, Predicted: positive\n",
      "Sample 4481: True: positive, Predicted: positive\n",
      "Sample 4858: True: neutral, Predicted: neutral\n",
      "Sample 2003: True: positive, Predicted: positive\n",
      "Sample 7597: True: positive, Predicted: positive\n",
      "Sample 4239: True: positive, Predicted: positive\n",
      "Sample 8110: True: positive, Predicted: positive\n",
      "Sample 5552: True: negative, Predicted: negative\n",
      "Sample 540: True: positive, Predicted: positive\n",
      "Sample 3666: True: negative, Predicted: negative\n",
      "Sample 8371: True: negative, Predicted: negative\n",
      "Sample 5588: True: neutral, Predicted: negative\n",
      "Sample 4759: True: negative, Predicted: negative\n",
      "Sample 2444: True: positive, Predicted: positive\n",
      "Sample 3667: True: negative, Predicted: negative\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in test_loader:\n",
    "        batch_x, batch_y = batch_x.to(\"mps\"), batch_y.to(\"mps\")\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        test_loss += loss.item() * batch_x.size(0)\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "test_loss /= total\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['negative', 'neutral', 'positive']))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n",
    "\n",
    "\n",
    "indices = random.sample(range(len(all_labels)), 20)\n",
    "for i in indices:\n",
    "    print(f\"Sample {i+1}: True: {['negative', 'neutral', 'positive'][all_labels[i]]}, Predicted: {['negative', 'neutral', 'positive'][all_preds[i]]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:18:33.823331Z",
     "start_time": "2025-06-16T21:18:33.256517Z"
    }
   },
   "id": "1f3936ff9c9a30e0",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Loss: 0.2784\n",
      "Train Accuracy: 0.9015\n",
      "\n",
      "Classification Report (Train):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.95      0.91     10058\n",
      "     neutral       0.87      0.80      0.83      9318\n",
      "    positive       0.95      0.93      0.94     15305\n",
      "\n",
      "    accuracy                           0.90     34681\n",
      "   macro avg       0.89      0.89      0.89     34681\n",
      "weighted avg       0.90      0.90      0.90     34681\n",
      "\n",
      "Confusion Matrix (Train):\n",
      "\n",
      "[[ 9578   375   105]\n",
      " [ 1149  7482   687]\n",
      " [  318   781 14206]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "train_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(\"mps\"), batch_y.to(\"mps\")\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        train_loss += loss.item() * batch_x.size(0)\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "train_loss /= total\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"\\nTrain Loss: {train_loss:.4f}\")\n",
    "print(f\"Train Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "\n",
    "print(\"Classification Report (Train):\\n\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['negative', 'neutral', 'positive']))\n",
    "\n",
    "print(\"Confusion Matrix (Train):\\n\")\n",
    "print(confusion_matrix(all_labels, all_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-16T21:18:45.099465Z",
     "start_time": "2025-06-16T21:18:43.348626Z"
    }
   },
   "id": "7dfb9b4e42ca4aa1",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-19T12:41:45.431771Z",
     "start_time": "2025-06-19T12:41:45.327455Z"
    }
   },
   "id": "6039bf7c15f2e711",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VaderSentimentAnalyzer' object has no attribute 'get_minimal_df'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      3\u001B[39m analyzer = VaderSentimentAnalyzer(\u001B[33m\"\u001B[39m\u001B[33mrealdonaldtrump.csv\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      4\u001B[39m analyzer.process()\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m minimal_df = \u001B[43manalyzer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_minimal_df\u001B[49m()\n\u001B[32m      6\u001B[39m minimal_df\n",
      "\u001B[31mAttributeError\u001B[39m: 'VaderSentimentAnalyzer' object has no attribute 'get_minimal_df'"
     ]
    }
   ],
   "source": [
    "from vader_sentiment_analyzer import VaderSentimentAnalyzer\n",
    "\n",
    "analyzer = VaderSentimentAnalyzer(\"realdonaldtrump.csv\")\n",
    "analyzer.process()\n",
    "minimal_df = analyzer.get_minimal_df()\n",
    "minimal_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-19T12:42:26.143927Z",
     "start_time": "2025-06-19T12:42:21.796915Z"
    }
   },
   "id": "7ccf3edbbe12bd27",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "abcf72e87bf86b46"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "myenv",
   "language": "python",
   "display_name": "Python (myenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
